{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4820a09-9d8f-46fe-9484-c67c7b94d16d",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc39b011-de8e-49f5-8cb9-cab972eaccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085b3dc-7e42-48cc-a31f-3bf8679b1035",
   "metadata": {},
   "source": [
    "Preprocessing Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73d2d79-7a4f-456a-8c25-314b7e1f51cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\admin\\Documents\\Hafizh Kuliah\\Machine Learning\\Latihan ML\\Deep Learning\\CNN\\Tomato\\tomato\\train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace343e4-147d-4b8e-8030-8ce059309a06",
   "metadata": {},
   "source": [
    "Preprocessing Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1bcda7-e318-4011-ae1a-059ddf725841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\admin\\Documents\\Hafizh Kuliah\\Machine Learning\\Latihan ML\\Deep Learning\\CNN\\Tomato\\tomato\\val',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e2ef67-ef9f-4719-b00f-5f1750ba667a",
   "metadata": {},
   "source": [
    "Create CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58db23f-ed43-47a1-8a6f-750e63989d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ed101-428f-4857-ada7-8d33602c3f19",
   "metadata": {},
   "source": [
    "Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3e48c5-3f2a-41b7-9b90-55bbaf95a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a7182e-87d4-428a-a3e7-efc7760c2a50",
   "metadata": {},
   "source": [
    "Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeba15d1-aba3-4860-9440-b020104f4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83226219-7406-435e-a574-edbec010e97a",
   "metadata": {},
   "source": [
    "Adding a Second Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef25844-f6bc-424a-a12d-59aaaec65703",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c3fa81-0e78-4246-b548-2f249519a754",
   "metadata": {},
   "source": [
    "Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bcb69e8-c91b-4f02-9451-c1520251ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d71189-b993-4121-8675-22c7950adba4",
   "metadata": {},
   "source": [
    "Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38fd7ccd-935b-4a79-be3e-0b5934aed2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ac556-dfc7-4181-8460-885f277fefb5",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1e04b3c-215f-4c50-b59c-c5ee333141da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8f1f9-4e89-4001-bc75-a865e850391e",
   "metadata": {},
   "source": [
    "Compiling The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaa9e173-e2f2-49ba-b39d-cd7b851aaaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400c79e-e561-4024-85cd-147047ddda65",
   "metadata": {},
   "source": [
    "Training The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f89fd229-df6c-4591-b213-b52fb72d4cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 2s/step - accuracy: 0.3310 - loss: 1.8779 - val_accuracy: 0.6560 - val_loss: 0.9922\n",
      "Epoch 2/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 543ms/step - accuracy: 0.7032 - loss: 0.8895 - val_accuracy: 0.6450 - val_loss: 1.0993\n",
      "Epoch 3/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 518ms/step - accuracy: 0.7625 - loss: 0.6780 - val_accuracy: 0.7300 - val_loss: 0.7765\n",
      "Epoch 4/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 515ms/step - accuracy: 0.8136 - loss: 0.5328 - val_accuracy: 0.7540 - val_loss: 0.7288\n",
      "Epoch 5/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 513ms/step - accuracy: 0.8391 - loss: 0.4704 - val_accuracy: 0.7520 - val_loss: 0.6791\n",
      "Epoch 6/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 510ms/step - accuracy: 0.8440 - loss: 0.4479 - val_accuracy: 0.8310 - val_loss: 0.5348\n",
      "Epoch 7/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 521ms/step - accuracy: 0.8684 - loss: 0.3788 - val_accuracy: 0.8580 - val_loss: 0.4473\n",
      "Epoch 8/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 541ms/step - accuracy: 0.8579 - loss: 0.4003 - val_accuracy: 0.8080 - val_loss: 0.6056\n",
      "Epoch 9/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 506ms/step - accuracy: 0.8815 - loss: 0.3396 - val_accuracy: 0.8210 - val_loss: 0.5306\n",
      "Epoch 10/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 297ms/step - accuracy: 0.8910 - loss: 0.3105 - val_accuracy: 0.8340 - val_loss: 0.5222\n",
      "Epoch 11/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 238ms/step - accuracy: 0.8950 - loss: 0.3101 - val_accuracy: 0.8010 - val_loss: 0.6390\n",
      "Epoch 12/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 273ms/step - accuracy: 0.9139 - loss: 0.2602 - val_accuracy: 0.7770 - val_loss: 0.6959\n",
      "Epoch 13/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 262ms/step - accuracy: 0.9055 - loss: 0.2752 - val_accuracy: 0.8030 - val_loss: 0.6530\n",
      "Epoch 14/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 235ms/step - accuracy: 0.9179 - loss: 0.2428 - val_accuracy: 0.8420 - val_loss: 0.5268\n",
      "Epoch 15/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 232ms/step - accuracy: 0.9151 - loss: 0.2444 - val_accuracy: 0.8260 - val_loss: 0.5892\n",
      "Epoch 16/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 217ms/step - accuracy: 0.9271 - loss: 0.2077 - val_accuracy: 0.8450 - val_loss: 0.4662\n",
      "Epoch 17/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 210ms/step - accuracy: 0.9253 - loss: 0.2083 - val_accuracy: 0.8610 - val_loss: 0.4525\n",
      "Epoch 18/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 247ms/step - accuracy: 0.9289 - loss: 0.2017 - val_accuracy: 0.8090 - val_loss: 0.6908\n",
      "Epoch 19/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 328ms/step - accuracy: 0.9349 - loss: 0.1934 - val_accuracy: 0.8390 - val_loss: 0.5161\n",
      "Epoch 20/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 311ms/step - accuracy: 0.9378 - loss: 0.1811 - val_accuracy: 0.8210 - val_loss: 0.6291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x277fdf883b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(training_set, validation_data=test_set, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
